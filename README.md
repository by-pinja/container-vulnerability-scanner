# container-vulnerability-scanner

Common simple rest API to scan docker images.

```ascii
              +---------------+
              |               | Offers common api for reporting and scanning.
              | CONTAINER-V-S | Communicates with clair and reports result.
              | API           |
              |               |
    +-------> |               | <-------+
    |         +-+-------+-----+         |
    |           ^       ^               | Requests to scan images like node:9.0
    |           |       |               | with source environment meta information.
    |           |       |               |
+---+---+ +-----+-+ +---+---+       +---+----+
|Kube   | |Kube   | |Kube   |       |Azure   |
|Agent  | |Agent  | |Agent  |       |Agent   |
|       | |       | |       |       |        |
|       | |       | |       |  ...  |        |  ...
+-------+ +-------+ +-------+       +--------+

```

## Problem domain

Theres many ready to use registry scanners available now also integrated to container registeries like in dockerhub or GCR. However they only scan image when it's pushed and their results are often hard to integrate to CI chain. Another problem in common solutions is that basically there are containers around in different environments with different version, how to collect knowledge which of them needs to be updated because of current state of vurnerabilities? This also contains third party containers which are very commonly used as part of solutions.

We already tested CLAIR as valid solution for scanning. We want to use it in multiple locations: CI and montly production cluster scanning. Addition to this it is important that we can collect reports to single point instead of fragmented locations (like each registry by its own).

Responsibility to pushing new data to this service is by agents which are tailored for each docker container service type. For example k8s and azure web app containers are two very different use cases but both require constant monitoring. In kubernetes theres agent software running in each cluster which get all images from deployments and send them to api for analysis.

## Setting up local development

`compose` folder contains local instance for clair and klar template that development mode can call. Fist edit `dockerhub.env` file and add your dockerhub username and password. These are needed because without them images from dockerhub cannot be pull properly. File is ignored so your secrets should never get committed to CVS. This is temporary solution since actually we must support multiple targets as source (private and public repositories) in custom locations like GCR.

```bash
cd compose && docker-compose up
```

Then in another terminal

```bash
dotnet watch run
```

Navigate [http://localhost:5000/doc/](http://localhost:5000/doc/)
